{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complimentary-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import bs4\n",
    "import stringdist\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-contractor",
   "metadata": {},
   "source": [
    "# UK Enterococcus Paper Metadata\n",
    "\n",
    "## Add sample and project accessions to UK metadata\n",
    "\n",
    "Starting from table S2 in https://mbio.asm.org/content/9/6/e01780-18 which contains `run_accessions` for deposited raw sequencing data in ENA, use the ENA API to automatically add `study_accession` and `sample_accession`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "multiple-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table S2 from https://mbio.asm.org/content/9/6/e01780-18\n",
    "uk_metadata = pd.read_csv('inline-supplementary-material-3.csv', sep='\\t', skiprows=1)\n",
    "uk_metadata = uk_metadata.rename(columns={'Accession number': 'Run_accession', \n",
    "                                          'Isolate ID': 'Isolate_name'})\n",
    "\n",
    "# break into 500 accession chunks to more efficiently query the API\n",
    "api_responses = \"\"\n",
    "\n",
    "run_accessions = uk_metadata.loc[uk_metadata['Run_accession'].str.startswith('ERR'), 'Run_accession'].values\n",
    "for run_accession_chunk in [run_accessions[i:i + 500] for i in range(0, len(run_accessions), 500)]:\n",
    "    run_accession_chunk = \",\".join(run_accession_chunk)\n",
    "    api_response = requests.get(f\"https://www.ebi.ac.uk/ena/browser/api/xml/{run_accession_chunk}\")    \n",
    "    api_responses += api_response.text\n",
    "\n",
    "# parse combined xml records into a soup for easier traversal \n",
    "api_response_soup = bs4.BeautifulSoup(api_responses, 'lxml')\n",
    "\n",
    "\n",
    "def add_study_and_sample_metadata(row, api_response_soup):\n",
    "    \"\"\"\n",
    "    Use the ENA API to get the study and sample accessions\n",
    "    \"\"\"\n",
    "    run_accession = row['Run_accession']\n",
    "        \n",
    "    run_soup = api_response_soup.find(accession=run_accession)\n",
    "    if run_soup:\n",
    "        for xref in run_soup.find_all('xref_link'):\n",
    "            if xref.db.text == 'ENA-STUDY':\n",
    "                row['Study_accession'] = xref.id.text.strip()\n",
    "            elif xref.db.text == 'ENA-SAMPLE':\n",
    "                row['Sample_accession'] = xref.id.text.strip()\n",
    "    else:\n",
    "        row['Study_accession'] = np.nan\n",
    "        row['Sample_accession'] = np.nan\n",
    "    return row\n",
    "\n",
    "uk_metadata = uk_metadata.apply(lambda x: add_study_and_sample_metadata(x, api_response_soup), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-auction",
   "metadata": {},
   "source": [
    "Then we want to clean up the column names to make merging easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sixth-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy up UK metadata for merging\n",
    "uk_metadata = uk_metadata.rename(columns={'Origin': 'Origin',\n",
    "                                          'BAPS group': 'BAPS_group',\n",
    "                                          'Location': 'Location',\n",
    "                                          'Ampicillin resistance': 'Ampicillin',\n",
    "                                          'Vancomycin resistance': 'Vancomycin'})\n",
    "\n",
    "#uk_metadata.loc[uk_metadata['Removed in deduplication'] == 'removed', 'Status'] = 'Removed for deduplication in original paper (10.1128/mBio.01780-18)'\n",
    "#uk_metadata = uk_metadata.drop('Removed in deduplication', axis=1)\n",
    "\n",
    "# all in this paper are E. faecium\n",
    "uk_metadata['Species'] = 'Enterococcus faecium'\n",
    "uk_metadata['Country/province'] = 'United Kingdom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "essential-nevada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Isolate_name</th>\n",
       "      <th>Run_accession</th>\n",
       "      <th>Origin</th>\n",
       "      <th>BAPS_group</th>\n",
       "      <th>ST</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ampicillin</th>\n",
       "      <th>Vancomycin</th>\n",
       "      <th>Removed in deduplication</th>\n",
       "      <th>Study_accession</th>\n",
       "      <th>Sample_accession</th>\n",
       "      <th>Species</th>\n",
       "      <th>Country/province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10678_8#11</td>\n",
       "      <td>ERR369948</td>\n",
       "      <td>Human invasive infection</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>Hospital 34</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERP003621</td>\n",
       "      <td>ERS325719</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10678_8#14</td>\n",
       "      <td>ERR369951</td>\n",
       "      <td>Human invasive infection</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>Hospital 1</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERP003621</td>\n",
       "      <td>ERS325652</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10678_8#17</td>\n",
       "      <td>ERR369954</td>\n",
       "      <td>Human invasive infection</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>Hospital 1</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERP003621</td>\n",
       "      <td>ERS325617</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10678_8#18</td>\n",
       "      <td>ERR369955</td>\n",
       "      <td>Human invasive infection</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>Hospital 1</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERP003621</td>\n",
       "      <td>ERS325952</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10678_8#19</td>\n",
       "      <td>ERR369956</td>\n",
       "      <td>Human invasive infection</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>Hospital 1</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERP003621</td>\n",
       "      <td>ERS325629</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>EFE10021</td>\n",
       "      <td>LN999844.1</td>\n",
       "      <td>Reference strain</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>Enterococcus faecium 6E6</td>\n",
       "      <td>CP013994</td>\n",
       "      <td>Reference strain</td>\n",
       "      <td>9</td>\n",
       "      <td>203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>NRRL_B_2354</td>\n",
       "      <td>CP004063</td>\n",
       "      <td>Reference strain</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>T110</td>\n",
       "      <td>CP006030</td>\n",
       "      <td>Reference strain</td>\n",
       "      <td>10</td>\n",
       "      <td>812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>UW8175</td>\n",
       "      <td>CP011828</td>\n",
       "      <td>Reference strain</td>\n",
       "      <td>5</td>\n",
       "      <td>904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1442 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Isolate_name Run_accession                    Origin  \\\n",
       "0                   10678_8#11     ERR369948  Human invasive infection   \n",
       "1                   10678_8#14     ERR369951  Human invasive infection   \n",
       "2                   10678_8#17     ERR369954  Human invasive infection   \n",
       "3                   10678_8#18     ERR369955  Human invasive infection   \n",
       "4                   10678_8#19     ERR369956  Human invasive infection   \n",
       "...                        ...           ...                       ...   \n",
       "1437                  EFE10021    LN999844.1          Reference strain   \n",
       "1438  Enterococcus faecium 6E6      CP013994          Reference strain   \n",
       "1439               NRRL_B_2354      CP004063          Reference strain   \n",
       "1440                      T110      CP006030          Reference strain   \n",
       "1441                    UW8175      CP011828          Reference strain   \n",
       "\n",
       "      BAPS_group   ST     Location Ampicillin      Vancomycin  \\\n",
       "0              2  117  Hospital 34          R               R   \n",
       "1              1  117   Hospital 1          R               R   \n",
       "2              1  186   Hospital 1          R               R   \n",
       "3              5   22   Hospital 1          S               S   \n",
       "4              1  132   Hospital 1          R               R   \n",
       "...          ...  ...          ...        ...             ...   \n",
       "1437           4   54          NaN        NaN  not applicable   \n",
       "1438           9  203          NaN        NaN  not applicable   \n",
       "1439           5   32          NaN        NaN  not applicable   \n",
       "1440          10  812          NaN        NaN  not applicable   \n",
       "1441           5  904          NaN        NaN  not applicable   \n",
       "\n",
       "     Removed in deduplication Study_accession Sample_accession  \\\n",
       "0                         NaN       ERP003621        ERS325719   \n",
       "1                         NaN       ERP003621        ERS325652   \n",
       "2                         NaN       ERP003621        ERS325617   \n",
       "3                         NaN       ERP003621        ERS325952   \n",
       "4                         NaN       ERP003621        ERS325629   \n",
       "...                       ...             ...              ...   \n",
       "1437                      NaN             NaN              NaN   \n",
       "1438                      NaN             NaN              NaN   \n",
       "1439                      NaN             NaN              NaN   \n",
       "1440                      NaN             NaN              NaN   \n",
       "1441                      NaN             NaN              NaN   \n",
       "\n",
       "                   Species Country/province  \n",
       "0     Enterococcus faecium   United Kingdom  \n",
       "1     Enterococcus faecium   United Kingdom  \n",
       "2     Enterococcus faecium   United Kingdom  \n",
       "3     Enterococcus faecium   United Kingdom  \n",
       "4     Enterococcus faecium   United Kingdom  \n",
       "...                    ...              ...  \n",
       "1437  Enterococcus faecium   United Kingdom  \n",
       "1438  Enterococcus faecium   United Kingdom  \n",
       "1439  Enterococcus faecium   United Kingdom  \n",
       "1440  Enterococcus faecium   United Kingdom  \n",
       "1441  Enterococcus faecium   United Kingdom  \n",
       "\n",
       "[1442 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-corpus",
   "metadata": {},
   "source": [
    "# AAFC Enterococcus Paper Metadata\n",
    "\n",
    "Raw sequencing data was not deposited for this paper so only a `BioProject` accession (`PRJNA604849`) i.e., `study_accession` above was provided, this study on NCBI contains `sample_accessions` and the raw assembly files.\n",
    "\n",
    "Therefore, download the metadata from this study and tidy up column names to make merging easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becoming-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PRJNA604849_full_biosample_list.xml') as fh:\n",
    "    PRJNA604849_xml = bs4.BeautifulSoup(fh, 'lxml')\n",
    "\n",
    "parsed_xml_data = {}\n",
    "for biosample in PRJNA604849_xml.find_all('biosample'):\n",
    "    biosample_data = {}\n",
    "    biosample_data['Sample_name'] = biosample.find(db_label='Sample name').text\n",
    "    biosample_data['Species'] = biosample.find('organismname').text\n",
    "    biosample_data['Strain_name'] = biosample.find(attribute_name=\"strain\").text\n",
    "    biosample_data['Study_accession'] = biosample.find(target=\"bioproject\")['label']\n",
    "    parsed_xml_data[biosample['accession']] = biosample_data\n",
    "    \n",
    "alberta_ncbi = pd.DataFrame(parsed_xml_data).T.reset_index().rename(columns={'index': 'Sample_accession'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-robinson",
   "metadata": {},
   "source": [
    "Now we need to parse and tidy up the metadata from https://www.nature.com/articles/s41598-020-61002-5  `41598_2020_61002_MOESM2_ESM.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "armed-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_metadata = pd.read_csv('41598_2020_61002_MOESM2_ESM.csv', sep='\\t')\n",
    "\n",
    "# drop the 2 inexplicably duplicated rows \n",
    "alberta_metadata = alberta_metadata.drop_duplicates()\n",
    "\n",
    "# get rid of the identical rows apart from _ vs - \n",
    "alberta_metadata = alberta_metadata[alberta_metadata['ISOLATE'] != 'SWEntR-0393']\n",
    "# identical row apart from incorrect species (when compared to NCBI assembly)\n",
    "alberta_metadata = alberta_metadata[alberta_metadata['ISOLATE'] != 'SWEntR 0262']\n",
    "\n",
    "\n",
    "# tidy columns up to help with merging later\n",
    "alberta_metadata = alberta_metadata.rename(columns={'ISOLATION SOURCE': 'Origin',\n",
    "                                                    'SPECIFIC LOCATION': 'Location',\n",
    "                                                    'VNCO': 'Vancomycin',\n",
    "                                                    'AMPI': 'Ampicillin',\n",
    "                                                    'TEIC': 'Teicoplanin',\n",
    "                                                    'DOXY': 'Doxycycline',\n",
    "                                                    'ERTH': 'Erythromycin',\n",
    "                                                    'GENT': 'Gentamicin',\n",
    "                                                    'LNZD': 'Linezolid',\n",
    "                                                    'LVFL': 'Levofloxacin',\n",
    "                                                    'QUIN': 'Quinolone',\n",
    "                                                    'STEP': 'Streptomycin',\n",
    "                                                    'NTRO': 'Nitrofurantoin',\n",
    "                                                    'TGC': 'Tigecycline',\n",
    "                                                    'SPECIATION': 'Species',\n",
    "                                                    'SOURCE CODE': 'Source_code',\n",
    "                                                    'ISOLATE': 'Isolate_name_paper'})\n",
    "\n",
    "# get rid of useless columns and add extra column to help with merging UK and AB metadata\n",
    "alberta_metadata = alberta_metadata.drop(['Unnamed: 18', \"Resistance count\", 'LOCATION'], axis=1)\n",
    "alberta_metadata['Province/country'] = 'Alberta/Canada'\n",
    "\n",
    "# Remove trailing spaces that were left in the paper metadata\n",
    "alberta_metadata['Species'] = alberta_metadata['Species'].str.strip()\n",
    "\n",
    "# To ensure we merge the correct identifiers we are going to use the Source_code\n",
    "# information AS WELL as the isolate_name, therefore let's create a new identifier\n",
    "# out of the source code and isolate_name (and then remove spaces/underscores/hyphens etc)\n",
    "def combine_source_and_isolate_name(row):\n",
    "    \"\"\"\n",
    "    Try to combine isolate name with the source code field\n",
    "    if it isn't already prefixed by the source code information\n",
    "    \"\"\"\n",
    "    # Spaces, hyphens and dashes are a major source of disconnect so just remove them and try to map\n",
    "    metadata_isolate_name = row['Isolate_name_paper'].replace('_', '').replace('-', '').replace(' ', '')\n",
    "    if metadata_isolate_name.startswith(row['Source_code']):\n",
    "        return metadata_isolate_name\n",
    "    else:\n",
    "        return row['Source_code'] +  metadata_isolate_name\n",
    "\n",
    "\n",
    "alberta_metadata['Source_code_and_isolate_name'] = alberta_metadata.apply(\\\n",
    "                                                            combine_source_and_isolate_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-collar",
   "metadata": {},
   "source": [
    "Now we want to merge in the accession data from the bioproject.\n",
    "\n",
    "Unfortunately the `isolate_name`'s in the NCBI bioproject do not match the `isolate_name`'s in the paper metadata so this needs fixing. \n",
    "\n",
    "Fortunately, most are pretty similar and its obvious what the correct `isolate_name` should be for each entry in the paper metadata (the deposited names are the \"correct\" ones).\n",
    "\n",
    "Therefore, let's find the closest match between the two sets of names using levenshtein distances,\n",
    "after manual review this resulted in false positives so let's match all digits in the sample names as a safety check.\n",
    "\n",
    "After this we can manually review any remaining mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flush-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt_to_reconcile_names(biosample_associated_identifiers, paper_metadata_identifiers):\n",
    "    \"\"\"\n",
    "    Take a list of \"correct\" identifiers from the BioSamples and try to match them to the \n",
    "    paper metadata identifiers \n",
    "    \n",
    "    First find the closest matching string using levenshtein distances\n",
    "    Then as a safety move extract all digits and confirm they match between\n",
    "    the biosample identifier and the closest paper identifier\n",
    "    \n",
    "    returns: dictionary mapping likely paper identifiers to biosample identifiers\n",
    "             list of biosample identifiers without an obvious match for manual fixing\n",
    "    \"\"\"\n",
    "    closest_match_string_dists = {}\n",
    "    for deposited_isolate_name in biosample_associated_identifiers:\n",
    "        # hyphens dashes and spaces are a major source of error so remove\n",
    "        stripped_deposited_isolate_name = deposited_isolate_name.replace('_', '').replace('-', '').replace(' ', '')\n",
    "        \n",
    "        closest_isolate_name = []\n",
    "        for paper_metadata_isolate_name in paper_metadata_identifiers:\n",
    "            closest_isolate_name.append((paper_metadata_isolate_name, stringdist.rdlevenshtein_norm(stripped_deposited_isolate_name.lower(),\n",
    "                                                                   paper_metadata_isolate_name.lower())))\n",
    "        closest_isolate_name = sorted(closest_isolate_name, key=lambda x: x[1])\n",
    "        closest_match_string_dists[closest_isolate_name[0][0]] = deposited_isolate_name\n",
    "        \n",
    "    # now check the numerical parts match (sans any leading 0s) to avoid false positives\n",
    "    non_numerically_matching = []\n",
    "    closest_match_string_dist_and_numerical_match = {}\n",
    "    for closest_paper_isolate_name, deposited_isolate_name in closest_match_string_dists.items():\n",
    "        digits_in_paper_name = \"\".join(re.findall(r'\\d+', closest_paper_isolate_name))\n",
    "        digits_in_deposited_name = \"\".join(re.findall(r'\\d+', deposited_isolate_name))\n",
    "        if digits_in_deposited_name.lstrip('0') == digits_in_paper_name.lstrip('0'):\n",
    "            closest_match_string_dist_and_numerical_match[closest_paper_isolate_name] = deposited_isolate_name\n",
    "        else:\n",
    "            non_numerically_matching.append(deposited_isolate_name)\n",
    "            \n",
    "    return closest_match_string_dist_and_numerical_match, non_numerically_matching\n",
    "\n",
    "\n",
    "isolate_to_strain_matches, isolate_to_strain_mismatches = attempt_to_reconcile_names(alberta_ncbi['Strain_name'].values, alberta_metadata['Source_code_and_isolate_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-shame",
   "metadata": {},
   "source": [
    "Now for manual and semi-manual fixes of missing isolates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "short-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_mappings_from_isolate = {\n",
    "    'WW0145I': 'ES-C-ST001-01FEB16-0145I',\n",
    "    'FC0145J': 'ES-C-ST001-01FEB16-0145J',\n",
    "    'WW0145K': 'ES-C-ST001-01FEB16-0145K',\n",
    "    'WW0154I': 'ES-C-ST001-04JUL16-0154I',\n",
    "    'WW0134A': 'ES-C-ST001-05OCT15-0134A',\n",
    "    'WW0134B': 'ES-C-ST001-05OCT15-0134B',\n",
    "    'WW0134C': 'ES-C-ST001-05OCT15-0134C',\n",
    "    'WW0134E': 'ES-C-ST001-05OCT15-0134E',\n",
    "    'WW0134L': 'ES-C-ST001-05OCT15-0134L',\n",
    "    'WW0141E': 'ES-C-ST001-07DEC15-0141E',\n",
    "    'WW0141M': 'ES-C-ST001-07DEC15-0141M',\n",
    "    'FC0096K': 'ES-C-ST001-15JUN15-0096K',\n",
    "    'WW0039D': 'ES-C-ST001-25AUG14-0039D',\n",
    "    'WW0039E': 'ES-C-ST001-25AUG14-0039E',\n",
    "    'FC0117B': 'ES-C-ST001-25AUG15-0117B',\n",
    "    'WW0117D': 'ES-C-ST001-25AUG15-0117D',\n",
    "    'WW0117E': 'ES-C-ST001-25AUG15-0117E',\n",
    "    'WW0117I': 'ES-C-ST001-25AUG15-0117I',\n",
    "    'WW0117M': 'ES-C-ST001-25AUG15-0117M',\n",
    "    'WW0081E': 'ES-C-ST001-27APR15-0081E',\n",
    "    'WW0081L': 'ES-C-ST001-27APR15-0081L',\n",
    "    'WW0146B': 'ES-C-ST002-01FEB16-0146B',\n",
    "    'FC0146C': 'ES-C-ST002-01FEB16-0146C',\n",
    "    'WW0146D': 'ES-C-ST002-01FEB16-0146D',\n",
    "    'WW0135A': 'ES-C-ST002-05OCT15-0135A',\n",
    "    'FC0135B': 'ES-C-ST002-05OCT15-0135B',\n",
    "    'WW0135C': 'ES-C-ST002-05OCT15-0135C',\n",
    "    'WW0142A': 'ES-C-ST002-07DEC15-0142A',\n",
    "    'WW0142B': 'ES-C-ST002-07DEC15-0142B',\n",
    "    'WW0142C': 'ES-C-ST002-07DEC15-0142C',\n",
    "    'WW0142D': 'ES-C-ST002-07DEC15-0142D',\n",
    "    'WW0142E': 'ES-C-ST002-07DEC15-0142E',\n",
    "    'WW0142I': 'ES-C-ST002-07DEC15-0142I',\n",
    "    'WW0067A': 'ES-M-ST001-03MAR15-0067A',\n",
    "    'WW0152A': 'ES-M-ST001-03MAY16-0152A',\n",
    "    'WW0152E': 'ES-M-ST001-03MAY16-0152E',\n",
    "    'WW0152J': 'ES-M-ST001-03MAY16-0152J',\n",
    "    'WW0152L': 'ES-M-ST001-03MAY16-0152L',\n",
    "    'WW0152M': 'ES-M-ST001-03MAY16-0152M',\n",
    "    'WW0137A': 'ES-M-ST001-03NOV15-0137A',\n",
    "    'WW0137C': 'ES-M-ST001-03NOV15-0137C',\n",
    "    'WW0137E': 'ES-M-ST001-03NOV15-0137E',\n",
    "    'WW0147B': 'ES-M-ST001-08MAR16-0147B',\n",
    "    'WW0147E': 'ES-M-ST001-08MAR16-0147E',\n",
    "    'FC0147I': 'ES-M-ST001-08MAR16-0147I',\n",
    "    'WW0147L': 'ES-M-ST001-08MAR16-0147L',\n",
    "    'WW0147M': 'ES-M-ST001-08MAR16-0147M',\n",
    "    'WW0050M': 'ES-M-ST001-13OCT14-0050M',\n",
    "    'FC0124I': 'ES-M-ST001-15SEP15-0124I',\n",
    "    'WW0124J': 'ES-M-ST001-15SEP15-0124J',\n",
    "    'FC0124K': 'ES-M-ST001-15SEP15-0124K',\n",
    "    'WW0124M': 'ES-M-ST001-15SEP15-0124M',\n",
    "    'WW0060D': 'ES-M-ST001-23NOV14-0060D',\n",
    "    'WW0138B': 'ES-M-ST002-03NOV15-0138B',\n",
    "    'WW0138C': 'ES-M-ST002-03NOV15-0138C',\n",
    "    'WW0138D': 'ES-M-ST002-03NOV15-0138D',\n",
    "    'SS0026': 'HC_SS0026',\n",
    "    'CB0139J': 'CB_0139J',\n",
    "    'CBEntR0183': 'CB_0183',\n",
    "    'CBEntR0150': 'CB_0150',\n",
    "    'CBSWEntR0048': 'CB_0048',\n",
    "    'CB0127I': 'CB_0127I',\n",
    "    'CBEntR0158': 'CB_0158',\n",
    "    'CBEnt0179': 'CB_0179',\n",
    "    'CBSWEntR0225': 'CB_0225',\n",
    "    'CBSWEntR0235': 'CB_0235',\n",
    "    'CBSWEntR0244': 'CB_0244',\n",
    "    'CBEnt0261': 'CB_0261',\n",
    "    'CBSWEntR0271': 'CB_0271',\n",
    "    'CBSWEntR0278': 'CB_0278',\n",
    "    'CBSWEntR0303': 'CB_0303',\n",
    "    'CBSWEntR0309': 'CB_0309',\n",
    "    'CBSWEntR0338': 'CB_0338',\n",
    "    'CBSWEntR0376': 'CB_0376',\n",
    "    'CBSWEntR0379': 'CB_0379',\n",
    "    'CBSWEntR0383': 'CB_0383',\n",
    "    'CBSWEntR0385': 'CB_0385',\n",
    "    'CBSWEntR0386': 'CB_0386',\n",
    "    'CBSWEntR0396': 'CB_0396',\n",
    "    'CBSWEnt0932': 'CB_0932',\n",
    "    'CBSWEnt0933': 'CB_0933',\n",
    "    'CBSWEnt1134': 'CB_1134',\n",
    "    'CBSWEnt1208': 'CB_1208',\n",
    "    'CBSWEnt1210': 'CB_1210',\n",
    "    'CBSWEnt1216': 'CB_1216',\n",
    "    'NWSEntR0002': 'SW_0002',\n",
    "    'NWSEnt0025': 'SW_0025',\n",
    "    'NWSSWEnt1171': 'SWEnt-1171',\n",
    "    'NWSEnt0202': 'SW_0202',\n",
    "    'NWSEnt0269': 'SW_0269',\n",
    "    'NWSEnt0270': 'SW_0270',\n",
    "    'NWSSWEnR0285': 'SW_0285',\n",
    "    'NWSSWEntR0295': 'SW_0295',\n",
    "    'NWSSWEntR0325': 'SW_0325',\n",
    "    'NWSSWEntR0367': 'SW_0367',\n",
    "    'NWSSWEntR0374': 'SW_0374',\n",
    "    'NWSSWEnt0985': 'SW_0985',\n",
    "    'NWSSWEnt1073': 'SW_1073',\n",
    "    'CBSWEnt1223': 'CB_1223'}\n",
    "\n",
    "# update the mapping with the manual fixed\n",
    "isolate_to_strain_matches.update(manual_mappings_from_isolate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-bachelor",
   "metadata": {},
   "source": [
    "Unfortunately, this still leaves us with 12 isolates that are in the deposited NCBI data but don't seem to have any supplied metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unauthorized-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ncbi = alberta_ncbi[~alberta_ncbi['Strain_name'].isin(isolate_to_strain_matches.values())].sort_values('Strain_name')['Strain_name'].values\n",
    "# add a status to the NCBI data indicating missing\n",
    "alberta_ncbi.loc[alberta_ncbi['Strain_name'].isin(unresolved_ncbi), 'Status'] = 'No metadata in original paper (10.1038/s41598-020-61002-5)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-physics",
   "metadata": {},
   "source": [
    "Time to add the correct mappings to the paper metadata sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggressive-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate the incorrect isolate_names in the paper metadata to the correct ones deposited in NCBI\n",
    "alberta_metadata['Strain_name'] = alberta_metadata['Source_code_and_isolate_name'].apply(lambda x: isolate_to_strain_matches[x] if x in isolate_to_strain_matches else f\"UNMATCHED: {x}\")\n",
    "\n",
    "# add the 12 unresolved identifiers to the paper metadata before merging\n",
    "alberta_metadata = pd.concat([alberta_metadata, pd.DataFrame({'Strain_name': unresolved_ncbi})])\n",
    "\n",
    "alberta_merged = pd.merge(alberta_ncbi, alberta_metadata, \n",
    "                          validate='one_to_one', how='inner', \n",
    "                          on='Strain_name', suffixes=['_ncbi', '_paper'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-cedar",
   "metadata": {},
   "source": [
    "## Add the read information and identify which reads need to be change\n",
    "\n",
    "First lets parse the read data from deivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forward-mechanics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-59360e37e34a>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  uk_read_data['Run_accession'] = uk_read_data['Strain_name']\n"
     ]
    }
   ],
   "source": [
    "read_data = pd.read_csv('Enterococcus_reads.tsv', sep='\\t')\n",
    "read_data = read_data.rename(columns={'Sample_name': \"Strain_name\"})\n",
    "read_data = read_data.replace({'E_faecalis': 'Enterococcus faecalis',\n",
    "                               'E_faecium': 'Enterococcus faecium'})\n",
    "\n",
    "# split the datasets for now\n",
    "uk_read_data = read_data[read_data['Strain_name'].str.startswith('ERR')]\n",
    "uk_read_data['Run_accession'] = uk_read_data['Strain_name']\n",
    "alberta_read_data = read_data[~read_data['Strain_name'].str.startswith('ERR')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scheduled-paper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain_name</th>\n",
       "      <th>Species</th>\n",
       "      <th>Read_1</th>\n",
       "      <th>Read_2</th>\n",
       "      <th>Run_accession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>ERR1007500</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1007500_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1007500_2.fastq.gz</td>\n",
       "      <td>ERR1007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>ERR1007501</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1007501_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1007501_2.fastq.gz</td>\n",
       "      <td>ERR1007501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>ERR1036024</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1036024_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1036024_2.fastq.gz</td>\n",
       "      <td>ERR1036024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ERR1036025</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1036025_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1036025_2.fastq.gz</td>\n",
       "      <td>ERR1036025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>ERR1036026</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1036026_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR1036026_2.fastq.gz</td>\n",
       "      <td>ERR1036026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>ERR987645</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987645_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987645_2.fastq.gz</td>\n",
       "      <td>ERR987645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>ERR987646</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987646_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987646_2.fastq.gz</td>\n",
       "      <td>ERR987646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>ERR987647</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987647_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987647_2.fastq.gz</td>\n",
       "      <td>ERR987647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>ERR987650</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987650_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987650_2.fastq.gz</td>\n",
       "      <td>ERR987650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>ERR987652</td>\n",
       "      <td>Enterococcus faecium</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987652_1.fastq.gz</td>\n",
       "      <td>E_faecium_342/all_reads/ERR987652_2.fastq.gz</td>\n",
       "      <td>ERR987652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Strain_name               Species  \\\n",
       "382   ERR1007500  Enterococcus faecium   \n",
       "383   ERR1007501  Enterococcus faecium   \n",
       "384   ERR1036024  Enterococcus faecium   \n",
       "385   ERR1036025  Enterococcus faecium   \n",
       "386   ERR1036026  Enterococcus faecium   \n",
       "...          ...                   ...   \n",
       "1045   ERR987645  Enterococcus faecium   \n",
       "1046   ERR987646  Enterococcus faecium   \n",
       "1047   ERR987647  Enterococcus faecium   \n",
       "1048   ERR987650  Enterococcus faecium   \n",
       "1049   ERR987652  Enterococcus faecium   \n",
       "\n",
       "                                             Read_1  \\\n",
       "382   E_faecium_342/all_reads/ERR1007500_1.fastq.gz   \n",
       "383   E_faecium_342/all_reads/ERR1007501_1.fastq.gz   \n",
       "384   E_faecium_342/all_reads/ERR1036024_1.fastq.gz   \n",
       "385   E_faecium_342/all_reads/ERR1036025_1.fastq.gz   \n",
       "386   E_faecium_342/all_reads/ERR1036026_1.fastq.gz   \n",
       "...                                             ...   \n",
       "1045   E_faecium_342/all_reads/ERR987645_1.fastq.gz   \n",
       "1046   E_faecium_342/all_reads/ERR987646_1.fastq.gz   \n",
       "1047   E_faecium_342/all_reads/ERR987647_1.fastq.gz   \n",
       "1048   E_faecium_342/all_reads/ERR987650_1.fastq.gz   \n",
       "1049   E_faecium_342/all_reads/ERR987652_1.fastq.gz   \n",
       "\n",
       "                                             Read_2 Run_accession  \n",
       "382   E_faecium_342/all_reads/ERR1007500_2.fastq.gz    ERR1007500  \n",
       "383   E_faecium_342/all_reads/ERR1007501_2.fastq.gz    ERR1007501  \n",
       "384   E_faecium_342/all_reads/ERR1036024_2.fastq.gz    ERR1036024  \n",
       "385   E_faecium_342/all_reads/ERR1036025_2.fastq.gz    ERR1036025  \n",
       "386   E_faecium_342/all_reads/ERR1036026_2.fastq.gz    ERR1036026  \n",
       "...                                             ...           ...  \n",
       "1045   E_faecium_342/all_reads/ERR987645_2.fastq.gz     ERR987645  \n",
       "1046   E_faecium_342/all_reads/ERR987646_2.fastq.gz     ERR987646  \n",
       "1047   E_faecium_342/all_reads/ERR987647_2.fastq.gz     ERR987647  \n",
       "1048   E_faecium_342/all_reads/ERR987650_2.fastq.gz     ERR987650  \n",
       "1049   E_faecium_342/all_reads/ERR987652_2.fastq.gz     ERR987652  \n",
       "\n",
       "[668 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tribal-nurse",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/eda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6199b733ac18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muk_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Origin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Reference strain'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0muk_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/eda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/eda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Status'"
     ]
    }
   ],
   "source": [
    "uk_metadata.loc[(uk_metadata['Origin'] != 'Reference strain') & (~uk_metadata['Status'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_metadata.loc[~uk_metadata['Status'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-relevance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.merge(uk_metadata, uk_read_data, on='Run_accession', how='left')\n",
    "df[df['Strain_name'].isna()]['Origin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-correction",
   "metadata": {},
   "source": [
    "Now merge the read information with the UK metadata as this should be easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(uk_metadata, read_data, validate=\"one_to_one\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dataa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-prayer",
   "metadata": {},
   "source": [
    "Identify what read information isn't readily mappable to the merged alberta metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alberta_metadata = alberta_metadata.drop(['Isolate_name_paper', 'Species_paper', 'Source_code_and_isolate_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_read_data[alberta_read_data['Strain_name'].isin(alberta_merged['Isolate_name_paper'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-interface",
   "metadata": {},
   "source": [
    "# Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-apartment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-polymer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
